# -*- coding: utf-8 -*-
"""Face Prediction One-Shot Learning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SElZbzv89JjSo2MQdsydWIG9SUo-Qhsj
"""

from google.colab import drive
drive.mount('/content/drive/')

import os
os.chdir('/content/drive/My Drive/face-recognition')
os.getcwd()

from model import create_model

nn4_pre= create_model()
nn4_pre.load_weights('weights/nn4.small2.v1.h5')

import numpy as np

class identityMetadata():
    def __init__(self,base,name,file):
        self.base=base
        self.name=name
        self.file=file

    def image_path(self):
        return os.path.join(self.base,self.name,self.file)


def load_metadata(path):
  metadata=[]
  for i in sorted(os.listdir(path)):
       for j in sorted(os.listdir(os.path.join(path,i))):
             metadata.append(identityMetadata(path,i,j))
  return np.array(metadata)


metadata= load_metadata('images')

import cv2
import matplotlib.pyplot as plt
import matplotlib.patches as patches

from align import AlignDlib

def load_image(path):
  img= cv2.imread(path,1)
  return img[:,:,::-1]


alignment= AlignDlib('/content/drive/My Drive/face-recognition/models/landmarks.dat')

org=load_image(metadata[5].image_path())

bb= alignment.getLargestFaceBoundingBox(org)

alg= alignment.align(96,org,bb,landmarkIndices=AlignDlib.OUTER_EYES_AND_NOSE)


plt.imshow(alg)

def align(img):
  return alignment.align(96,img,alignment.getLargestFaceBoundingBox(img),landmarkIndices=AlignDlib.OUTER_EYES_AND_NOSE)

embedded= np.zeros((metadata.shape[0],128))
print(embedded.shape)
length=len(metadata)
for i in range(length):
  img=load_image(metadata[i].image_path())
  img= align(img)

  img=(img/255).astype(np.float32)

  embedded[i]=nn4_pre.predict(np.expand_dims(img,axis=0))

def edistance(emb1,emb2):
  return np.sum(np.square(emb1-emb2))

def showDistance(id1,id2):
  plt.figure(figsize=(8,5))
  print(edistance(embedded[id1],embedded[id2]))
  plt.subplot(121)
  plt.imshow(load_image(metadata[id1].image_path()))
  plt.subplot(122)
  plt.imshow(load_image(metadata[id2].image_path()))
showDistance(0,1)
showDistance(1,2)

from sklearn.metrics import f1_score,accuracy_score

distances=[]
identicle=[]

n=len(metadata)

for i in range(n-1):
  for j in range(i+1,n):
    distances.append(edistance(embedded[i],embedded[j]))
    identicle.append(1 if metadata[i].name==metadata[j].name else 0)


distances=np.array(distances)
identicle=np.array(identicle)

threshold=np.arange(0.3,1.0,0.01)

acc=[accuracy_score(identicle,distances<t) for t in threshold]

max_accuracy_index=np.argmax(acc)

f_threshold=threshold[max_accuracy_index]

print("Threshold is "+str(f_threshold))

plt.plot(threshold,acc)

from sklearn.preprocessing import LabelEncoder
from sklearn.neighbors import KNeighborsClassifier


enc= LabelEncoder()

targets= [m.name for m in metadata]
enc.fit(targets)

cl= enc.transform(targets)

train_indexes=np.arange(metadata.shape[0]) % 2==0
test_indexes= np.arange(metadata.shape[0]) %2 !=0

trainx=embedded[train_indexes]
trainy=cl[train_indexes]

testx=embedded[test_indexes]
testy=cl[test_indexes]

knn= KNeighborsClassifier(n_neighbors=1,metric='euclidean')

knn.fit(trainx,trainy)
aa= accuracy_score(testy,knn.predict(testx))

print("Achieved Accuracy -  "+ str(aa))

"""Final Prediction from Model"""

def getFaceIdentity(index):

 test_img=load_image(metadata[test_indexes][index].image_path())
 pred=knn.predict([embedded[test_indexes][index]])
 identity= enc.inverse_transform(pred)

 print("The Person is -  "+str(identity))

 plt.imshow(test_img)

getFaceIdentity(5)